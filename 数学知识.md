## 相关数学基础

#### 多元积分换元法

多元积分换元法：$x=\phi(y):R^n \to R^n$
$$
\int_D f(x)dx = 
\int_{D'}f(y)|det(\frac{\partial x}{\partial y})|dy 
$$

其中编导数矩阵

$$
\frac{\partial x}{\partial y} = 
\begin{bmatrix}
\frac{\partial x_1}{\partial y_1} & \frac{\partial x_1}{\partial y_2} & \cdots & \frac{\partial x_1}{\partial y_n} \\\\
\frac{\partial x_2}{\partial y_1} & \frac{\partial x_2}{\partial y_2} & \cdots & \frac{\partial x_2}{\partial y_n} \\\\
\vdots&\vdots&\ddots&\vdots \\\\
\frac{\partial x_n}{\partial y_1} & \frac{\partial x_n}{\partial y_2} & \cdots & \frac{\partial x_n}{\partial y_n}
\end{bmatrix}
$$
称为雅可比矩阵

推导如下：
多元变量$x: R^n \to R$全微分定义为

$$
\begin{split}
dx & =\frac{\partial x}{\partial y_1}dy_1+ \frac{\partial x}{\partial y_2}dy_2+\cdots+\frac{\partial x}{\partial y_n}dy_n \\\\
& =(\frac{\partial x}{\partial y_1}, \frac{\partial x}{\partial y_2},\cdots,\frac{\partial x}{\partial y_n})
\begin{pmatrix}
dy_1 \\\\
dy_2 \\\\
\cdots \\\\
dy_n
\end{pmatrix}
\end{split}
$$

于是对于$x=\phi(y), R^n \to R^n$，令$x_i=\phi_i(y)=\pi_i \circ \phi (y)$

$$
\begin{pmatrix}
dx_1 \\\\
dx_2 \\\\
\cdots \\\\
dx_n
\end{pmatrix}=
\begin{bmatrix}
\frac{\partial x_1}{\partial y_1} & \frac{\partial x_1}{\partial y_2} & \cdots & \frac{\partial x_1}{\partial y_n} \\\\
\frac{\partial x_2}{\partial y_1} & \frac{\partial x_2}{\partial y_2} & \cdots & \frac{\partial x_2}{\partial y_n} \\\\
\vdots&\vdots&\ddots&\vdots \\\\
\frac{\partial x_n}{\partial y_1} & \frac{\partial x_n}{\partial y_2} & \cdots & \frac{\partial x_n}{\partial y_n}
\end{bmatrix}
\begin{pmatrix}
dy_1 \\\\
dy_2 \\\\
\cdots \\\\
dy_n
\end{pmatrix}
$$

因此把坐标系转换后两者大小的比例刚好是行列式绝对值代表的容积。

对于二维直角坐标系对应的极坐标系有$x=r\circ cos(\theta),y=r \circ sin(\theta)$，雅可比矩阵为：

$$
\begin{bmatrix}
cos(\theta) & -r \circ sin(\theta) \\\\
sin(\theta) & r \circ cos(\theta)
\end{bmatrix}=r
$$

#### 高斯积分和高斯分布

对二维标准高斯分布做极坐标系转换得到：
$$
\begin{split}
\iint e^{-x^2-y^2}dxdy & = \int_0^{2\pi} \int_0^{+\infty}e^{-r^2}rdrd\theta \\\\
& = \int_0^{2\pi} [-\frac{1}{2} \int_{0}^{-\infty}e^{-r^2}d(-r^2)]d\theta \\\\
& = \int_0^{2\pi}[-\frac{1}{2}e^{-r^2}\Bigg\lvert_{0}^{+\infty}]d\theta \\\\
& = \int_0^{2\pi}\frac{1}{2}d\theta \\\\
& = \pi
\end{split}
$$

另一方面
$$
\begin{split}
\iint e^{-x^2-y^2}dxdy & = [\int e^{-x^2}dx] \circ [\int e^{-y^2}dy] \\\\
& = [\int e^{-x^2}dx] ^2 = \pi
\end{split}
$$

因此高斯积分$\int e^{-x^2}dx=\sqrt{\pi}$


正态分布的概率密度合理化证明：
$\int_{-\infty}^{+\infty} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2} } dx =1 ?$

令$y=\frac{(x-\mu)}{\sqrt{2}\sigma}$,$dx=\sqrt{2}\sigma dy$

$$
\begin{split}
\int_{-\infty}^{+\infty} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2} } dx & = \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-y^2 } \sqrt{2}\sigma dy \\\\
& = \frac{1}{\sqrt\pi} \int_{-\infty}^{+\infty} e^{-y^2}dy = 1
\end{split}
$$


正态分布的熵：
$$
\begin{split}
H(p) & = - \int p(x) ln[p(x)] dx \\\\
& = -\int p(x) ln[\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2} }] dx \\\\
& = \int \frac{(x-\mu)^2}{2\sigma^2} p(x)dx + \int ln[\sqrt{2 \pi \sigma^2}] p(x) dx \\\\
&= \frac{1}{2\sigma^2} \int (x-\mu)^2 p(x) dx + ln[\sqrt{2 \pi \sigma^2}] \int p(x) dx \\\\
&= \frac{1}{2\sigma^2} E_{x \sim p(x)}[(x-\mu)^2] + ln[\sqrt{2 \pi \sigma^2}] \\\\
&= \frac{1}{2\sigma^2} \sigma^2 + ln[\sqrt{2 \pi \sigma^2}]= ln[\sqrt{2 \pi \sigma^2}] + \frac 1 2
\end{split}
$$

KL散度非负，且当且仅当两个分布相同时为零：

$$
\begin{split}
& KL[p(x)//q(x)]=-E_{x \sim p(x)}[log\frac{q(x)}{p(x)}] \\\\
& log是上凸函数（凹函数），根据Jensen不等式 \\\\
& \geq - log \\{ E_{x \sim p(x)}[\frac{q(x)}{p(x)}] \\} = log \int p(x) \frac{q(x)}{p(x)} dx  \\\\
& = log 1 = 0
\end{split}
$$

正态分布的KL散度：

$$
\begin{split}
& KL[p//q] = -E_{x \sim p(x)}[ln\frac{q(x)}{p(x)}] = -E_{x \sim p(x)}[ln[q(x)]+ln[p(x)]] \\\\&
= -E_{x \sim p(x)}[ln[q(x)]] - H(p)= -\int p(x) ln[q(x)] dx - H(p) \\\\&
= -\int p(x) ln [\frac{1}{\sqrt{2 \pi \sigma_q^2}} e^{- \frac{(x-\mu_q)^2}{2\sigma_q^2}  }] dx -H(p) \\\\&
= \int p(x) ln[\sqrt{2 \pi \sigma_q^2}] dx + \int  \frac{(x-\mu_q)^2}{2\sigma_q^2} p(x) dx  -H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \int [ (x-\mu_p) + (\mu_p-\mu_q) ]^2 p(x) dx + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \int [ (x-\mu_p)^2 +2(x-\mu_p)(\mu_p-\mu_q) + (\mu_p-\mu_q)^2 ] p(x) dx + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} [ \int (x-\mu_p)^2 p(x) dx + \int 2(x-\mu_p)(\mu_p-\mu_q) p(x)dx + \int (\mu_p-\mu_q)^2 p(x)dx] + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \\{E_{x \sim p(x)}[(x-\mu_p)^2] + E_{x \sim p(x)}[2(x-\mu_p)(\mu_p-\mu_q)] + E_{x \sim p(x)}[(\mu_p-\mu_q)^2] \\} + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \\{\sigma_p^2+ 2(\mu_p-\mu_q)E_{x \sim p(x)}[x-\mu_p] + (\mu_p-\mu_q)^2 \\} + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \\{\sigma_p^2+ 2(\mu_p-\mu_q)E_{x \sim p(x)}[x]-2\mu_p(\mu_p-\mu_q) + (\mu_p-\mu_q)^2 \\} + ln(\sqrt{2 \pi \sigma_q^2}) - H(p) \\\\&
= \frac{1}{2 \sigma_q^2} \\{\sigma_p^2+ 2(\mu_p-\mu_q)\mu_p-2\mu_p(\mu_p-\mu_q) + (\mu_p-\mu_q)^2 \\} + ln(\sqrt{2 \pi \sigma_q^2}) - H(p)\frac{1}{2 \sigma_q^2} \\{\sigma_p^2 + (\mu_p-\mu_q)^2 \\} + ln(\sqrt{2 \pi \sigma_q^2}) - (\frac 1 2 + ln(\sqrt{2 \pi \sigma_p^2})) \\\\&
= \frac{\sigma_p^2}{2 \sigma_q^2} + \frac{(\mu_p-\mu_q)^2}{2\sigma_q^2} +  ln(\frac{\sigma_q}{\sigma_p}) - \frac 1 2 \\\\&
= \frac 1 2 [\frac{\sigma_p^2}{\sigma_q^2} - ln(\frac{\sigma_p^2}{\sigma_q^2}) + \frac{(\mu_p-\mu_q)^2}{\sigma_q^2} - 1 ]
\end{split}
$$

正态分布的交叉熵 $CrossEntropy(p//q)$ 记为 $H(p // q)$，根据定义：

$$KL(p//q) = H(p//q) - H(p)$$

因此
$$
\begin{split}
& H(p//q) =KL(p//q)+H(p) = \\\\
&=\frac 1 2 [\frac{\sigma_p^2}{\sigma_q^2} - ln(\frac{\sigma_p^2}{\sigma_q^2}) + \frac{(\mu_p-\mu_q)^2}{\sigma_q^2} - 1 ] + (ln[\sqrt{2 \pi \sigma_p^2}] + \frac 1 2) \\\\
&=\frac 1 2 [\frac{\sigma_p^2}{\sigma_q^2} - ln(\frac{\sigma_p^2}{\sigma_q^2}) + \frac{(\mu_p-\mu_q)^2}{\sigma_q^2} +ln(\sigma_p^2) + ln(2\pi) ] \\\\
&=\frac 1 2 [\frac{\sigma_p^2}{\sigma_q^2} + ln(\sigma_q^2) + \frac{(\mu_p-\mu_q)^2}{\sigma_q^2} + ln(2\pi) ]
\end{split}
$$

#### 幂均值函数及其不等式
幂均值函数定义为，给定$x_i \geq 0$：
$$
M(p) = (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p}
$$

幂均值函数与最大最小值
$$
\begin{split}
\lim\limits_{p \rightarrow 0} M(p) & = \prod\limits_{k=1}^{n}x_i^{\frac 1 n} \\\\
\lim\limits_{p \rightarrow \infty} M(p) & = max\\{ x_i \\} \\\\
\lim\limits_{p \rightarrow -\infty} M(p) & = min\\{ x_i \\}
\end{split}
$$
第一个极限使用洛必达法则证明，后面两个极限是对偶的，使用夹逼定理证明：
$$
\begin{split}
&\lim\limits_{p \rightarrow 0} M(p) \\\\
= & \lim\limits_{p \rightarrow 0} (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \\\\
= & \lim\limits_{p \rightarrow 0} e^{ln(\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p}} \\\\
= & e^{\lim\limits_{p \rightarrow 0} ln(\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p}} \\\\
= & e^{\lim\limits_{p \rightarrow 0} {\frac {ln(\frac {\sum\limits_{k=1}^{n}x_i^p} n)} p}} \\\\
= & e^{\lim\limits_{p \rightarrow 0} {\frac {ln(\frac {\sum\limits_{k=1}^{n}x_i^p} n)'} {p'}}} \\\\
= & e^{\lim\limits_{p \rightarrow 0} {\frac {(\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{-1}(\frac {\sum\limits_{k=1}^{n}x_i^p} n)'} {1}}} \\\\
= & e^{\lim\limits_{p \rightarrow 0} {\frac {\sum\limits_{k=1}^{n}ln(x_i)x_i^p} {\sum\limits_{k=1}^{n}x_i^p}}} \\\\
= & e^{ {\frac {\sum\limits_{k=1}^{n}ln(x_i)x_i^0} {\sum\limits_{k=1}^{n}x_i^0}}} \\\\
= & e^{ \frac {\sum\limits_{k=1}^n ln(x_i)} n }=\prod\limits_{k=1}^{n}x_i^{\frac 1 n}
\end{split}
$$
第二个极限，记$X_M=max\\{ x_i \\}$：
$$
\begin{split}
(\frac {X_M^p} n)^{\frac 1 p} \leq (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \leq (\frac {\sum\limits_{k=1}^{n}X_M^p} n)^{\frac 1 p} \\\\
X_M(\frac 1 n)^{\frac 1 p} \leq M(p) \leq X_M \\\\
\lim\limits_{p \rightarrow \infty} X_M(\frac 1 n)^{\frac 1 p} \leq \lim\limits_{p \rightarrow \infty} M(p) \leq X_M \\\\
\lim\limits_{p \rightarrow \infty} X_M(\frac 1 n)^{\frac 1 p} \leq \lim\limits_{p \rightarrow \infty} M(p) \leq X_M \\\\
X_M \leq \lim\limits_{p \rightarrow \infty} M(p) \leq X_M
\end{split}
$$
第三个极限只要利用$p \rightarrow -\infty <=> q=(-p) \rightarrow \infty $以及$[max\\{ x_i^{-1} \\} ] ^{-1}=min\\{ x_i \\}$

幂均值函数是递增函数，并且有：
$$
\begin{split}
M(-1) = H_n & = (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \quad 调和平均 \\\\
M(0) = G_n & = (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \quad 几何平均 \\\\
M(1) = A_n & = (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \quad 算术平均 \\\\
M(1)= Q_n & = (\frac {\sum\limits_{k=1}^{n}x_i^p} n)^{\frac 1 p} \quad 平方平均 \\\\
min \leq H_n  & \leq G_n\leq A_n \leq Q_n \leq max
\end{split}
$$

TODO 递增证明

#### 柯西不等式和对数不等式
柯西不等式有限元版本：给定两个向量$a,b \in R^n$，则
$$
|a| \cdot |b| \geq |a \cdot b|
$$
这个也是线性代数关于模长的性质：$\frac {|a \cdot b|} {|a| \cdot |b|} = cos(\theta)$，其中$\theta$是两个向量的夹角。

柯西不等式积分版本：给定两个可积函数$f(x)$和$g(x)$：
$$
\int_{a}^{b}|f(x)|^2 dx \cdot \int_{a}^{b}|g(x)|^2 dx \geq |\int_{a}^{b}f(x) g(x) dx |^2
$$

证明对数不等式，给定$b > a > 0$，$(ab)^{\frac 1 2} \leq \frac {b-a} {ln(b) - ln(a)} \leq \frac {a+b} 2$。

有多种证明方法，使用柯西不等式积分版本是最直观的一种。
令$f(x)=\sqrt{x},g(x)=\frac 1 {\sqrt{x}}$，代入柯西不等式有：
$$
\begin{split}
\int_{a}^{b}x dx \cdot \int_{a}^{b} \frac 1 x dx \geq |\int_{a}^{b} dx |^2 \\\\
(b^2/2-a^2/2) \cdot (ln(b)-ln(a)) \geq (b-a)^2 \\\\
\frac {a+b} 2 \geq \frac {b-a} {ln(b) - ln(a)}
\end{split}
$$
令$f(x)=\frac 1 x,g(x)=1$，代入柯西不等式有：
$$
\begin{split}
\int_{a}^{b} {\frac 1 {x^2}} dx \cdot \int_{a}^{b} dx \geq |\int_{a}^{b} \frac 1 x dx |^2 \\\\
(-b^{-1}+a^{-1}) \cdot (b-a) \geq (ln(b)-ln(a))^2 \\\\
\frac {(b-a)^2} {ab} \geq (ln(b)-ln(a))^2 \\\\
\frac {(b-a)^2} {(ln(b)-ln(a))^2} \geq ab \\\\
\frac {b-a} {ln(b)-ln(a)} \geq \sqrt{ab}
\end{split}
$$

#### 最大值函数的平滑逼近
最大值函数$max(x,y)$不是光滑的，固定其中一个变量的值(例如$y$)，则在$x=y$点的导数不存在。

实现最大值函数的平滑逼近的主要思路如下：假设存在函数$f(x)$及其逆函数存在并处处可导，且对任意$k \in Int$有：$f^{-1}(k x)=g(k)+f^{-1}(x)$，其中$g(k)$不是无穷大。则$max \\{ x_i \\} =\lim\limits_{k \rightarrow +\infty}\frac {f^{-1}(\sum\limits_{l=1}^{n} f(k x_i)} k$。证明：
$$
\begin{split}
& \lim\limits_{k \rightarrow +\infty}\frac {f^{-1}(\sum\limits_{l=1}^{n} f(k x_i)} k \\\\
\leq & \lim\limits_{k \rightarrow +\infty}\frac {f^{-1}(f(k m)} k \\\\
= & \lim\limits_{k \rightarrow +\infty}\frac {g(n)+f^{-1}f(km)} k \\\\
= & \lim\limits_{k \rightarrow +\infty}\frac {g(n)} k + m = m \\\\
& \lim\limits_{k \rightarrow +\infty}\frac {f^{-1}(\sum\limits_{l=1}^{n} f(k x_i)} k  \\\\
\geq & \lim\limits_{k \rightarrow +\infty}\frac {f^{-1}(f(k m)} k = m
\end{split}
$$
固定$k$则其导数是：
$$
[\frac {f^{-1}(\sum\limits_{l=1}^{n} f(k x_i)} k]'\approx [\frac {f^{-1}f(km)} k]'= \frac {{f^{-1}}'[f(km)] f'(km)} k
$$

实际使用中指数/对数是常用的平滑选择。令$f(x)=e^x,f^{-1}(x)=ln(x)$，$k=1$，则$max\\{ x_i \\} \approx ln(\sum\limits_{l=1}^{n}e^{x_i})$。当$k$选一些更大的数时(例如10)则逼近效果更佳，然而导数的大小正比于$k$，可能导致数值计算溢出。
